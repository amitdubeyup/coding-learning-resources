# Node.js Best Practices (201-210)

### 201. What are the best practices for error handling in Node.js?
**Answer:**
- Use try/catch for synchronous and async/await code.
- Always handle errors in callbacks (first argument is usually `err`).
- Use a global error handler for uncaught exceptions and unhandled promise rejections.
- Create custom error classes for different error types.

```javascript
// Custom error class
class NotFoundError extends Error {
  constructor(message) {
    super(message);
    this.name = 'NotFoundError';
    this.status = 404;
  }
}

// Async/await error handling
app.get('/user/:id', async (req, res, next) => {
  try {
    const user = await User.findById(req.params.id);
    if (!user) throw new NotFoundError('User not found');
    res.json(user);
  } catch (err) {
    next(err);
  }
});

// Global error handler
app.use((err, req, res, next) => {
  res.status(err.status || 500).json({ error: err.message });
});
```

---

### 202. How do you implement logging in Node.js?
**Answer:**
- Use a logging library like `winston` or `pino` for structured logs.
- Log errors, warnings, and important events.
- Use different log levels (info, warn, error, debug).
- Log to files and/or external services in production.

```javascript
const winston = require('winston');
const logger = winston.createLogger({
  level: 'info',
  format: winston.format.json(),
  transports: [
    new winston.transports.File({ filename: 'error.log', level: 'error' }),
    new winston.transports.File({ filename: 'combined.log' })
  ]
});

logger.info('Server started');
logger.error('Something went wrong');
```

---

### 203. What are the best practices for security in Node.js?
**Answer:**
- Use `helmet` to set secure HTTP headers.
- Sanitize and validate all user input.
- Use parameterized queries to prevent SQL injection.
- Store secrets in environment variables, not in code.
- Keep dependencies up to date and audit them for vulnerabilities.

```javascript
const helmet = require('helmet');
app.use(helmet());

const { body, validationResult } = require('express-validator');
app.post('/register', [
  body('email').isEmail(),
  body('password').isLength({ min: 8 })
], (req, res) => {
  const errors = validationResult(req);
  if (!errors.isEmpty()) {
    return res.status(400).json({ errors: errors.array() });
  }
  // Continue registration
});
```

---

### 204. How do you implement caching in Node.js?
**Answer:**
- Use in-memory caching (e.g., `node-cache`) for small-scale apps.
- Use Redis or Memcached for distributed caching.
- Cache database query results, API responses, or computed data.

```javascript
const NodeCache = require('node-cache');
const cache = new NodeCache({ stdTTL: 60 });

app.get('/data', async (req, res) => {
  const cached = cache.get('data');
  if (cached) return res.json(cached);
  const data = await fetchData();
  cache.set('data', data);
  res.json(data);
});
```

---

### 205. What are the best practices for performance in Node.js?
**Answer:**
- Use asynchronous/non-blocking code.
- Use clustering or worker threads for CPU-bound tasks.
- Profile and monitor performance (e.g., with `clinic.js`).
- Minimize synchronous code and avoid blocking the event loop.
- Use caching and database indexing.

```javascript
// Example: Using cluster for multi-core utilization
const cluster = require('cluster');
const os = require('os');
if (cluster.isMaster) {
  for (let i = 0; i < os.cpus().length; i++) {
    cluster.fork();
  }
} else {
  // Worker code
  app.listen(3000);
}
```

---

### 206. How do you implement monitoring in Node.js?
**Answer:**
- Use tools like `pm2`, `New Relic`, or `Prometheus` for monitoring.
- Track metrics: CPU, memory, response time, error rates.
- Set up health check endpoints.

```javascript
// Health check endpoint
app.get('/health', (req, res) => {
  res.json({ status: 'ok', uptime: process.uptime() });
});

// PM2 monitoring
// pm2 start app.js --watch
// pm2 monit
```

---

### 207. What are the best practices for testing in Node.js?
**Answer:**
- Use frameworks like `mocha`, `jest`, or `ava`.
- Write unit, integration, and end-to-end tests.
- Mock external dependencies.
- Use CI to run tests automatically.

```javascript
// Example with Jest
const request = require('supertest');
const app = require('./app');

test('GET /health returns ok', async () => {
  const res = await request(app).get('/health');
  expect(res.statusCode).toBe(200);
  expect(res.body.status).toBe('ok');
});
```

---

### 208. How do you implement deployment in Node.js?
**Answer:**
- Use process managers like `pm2` or Docker containers.
- Set environment variables for configuration.
- Use CI/CD pipelines for automated deployment.
- Deploy to cloud providers (AWS, Azure, GCP) or PaaS (Heroku, Vercel).

```bash
# Example: Deploy with PM2
pm2 start app.js --name my-app
pm2 save
pm2 startup
```

---

### 209. What are the best practices for documentation in Node.js?
**Answer:**
- Use tools like JSDoc for code documentation.
- Maintain a clear and up-to-date README.
- Document API endpoints and usage examples.
- Use inline comments for complex logic.

```javascript
/**
 * Adds two numbers.
 * @param {number} a
 * @param {number} b
 * @returns {number}
 */
function add(a, b) {
  return a + b;
}
```

---

### 210. How do you implement maintenance in Node.js?
**Answer:**
- Regularly update dependencies and audit for vulnerabilities.
- Monitor logs and performance metrics.
- Refactor code for readability and maintainability.
- Write tests before refactoring.
- Use feature flags for safe rollouts.

```bash
# Check for outdated packages
npm outdated
# Audit for vulnerabilities
npm audit
```

# Advanced System Design with Node.js (211-220)

### 211. Design a distributed caching system that can handle 1M+ requests per second.
**Answer:**
- Use Redis or Memcached clusters for distributed caching.
- Partition data using consistent hashing.
- Use client-side sharding to distribute requests.
- Replicate data for high availability.
- Use connection pooling and pipelining for throughput.

```javascript
// Example: Using ioredis for Redis cluster
const Redis = require('ioredis');
const redis = new Redis.Cluster([
  { host: '10.0.0.1', port: 6379 },
  { host: '10.0.0.2', port: 6379 },
]);

// Set and get cache
await redis.set('user:123', JSON.stringify({ name: 'Alice' }), 'EX', 60);
const user = JSON.parse(await redis.get('user:123'));
```

---

### 212. How would you design a real-time notification system for a social media platform?
**Answer:**
- Use WebSockets (Socket.IO) for real-time delivery.
- Store notifications in a database (MongoDB, PostgreSQL).
- Use Redis Pub/Sub for broadcasting events to multiple servers.
- Queue notifications for offline users (RabbitMQ, Bull).

```javascript
// Example: Broadcasting notifications
io.on('connection', (socket) => {
  socket.on('subscribe', (userId) => {
    socket.join(`user:${userId}`);
  });
});

function sendNotification(userId, message) {
  io.to(`user:${userId}`).emit('notification', message);
}
```

---

### 213. Design a scalable file upload system that can handle millions of concurrent uploads.
**Answer:**
- Use a load balancer (NGINX) to distribute upload requests.
- Store files in object storage (Amazon S3, Google Cloud Storage).
- Use streaming to handle large files efficiently.
- Generate pre-signed URLs for direct client uploads.

```javascript
// Example: Streaming upload to S3
const AWS = require('aws-sdk');
const s3 = new AWS.S3();

app.post('/upload', (req, res) => {
  const upload = s3.upload({
    Bucket: 'my-bucket',
    Key: req.headers['file-name'],
    Body: req,
  });
  upload.send((err, data) => {
    if (err) return res.status(500).json({ error: err.message });
    res.json({ url: data.Location });
  });
});
```

---

### 214. How would you implement a distributed rate limiting system across multiple data centers?
**Answer:**
- Use a centralized data store (Redis) for rate limit counters.
- Use atomic operations (INCR, EXPIRE) for accuracy.
- Replicate Redis across data centers for low latency.
- Use a fallback mechanism if the rate limit store is unavailable.

```javascript
// Example: Distributed rate limiting with Redis
async function rateLimit(userId) {
  const key = `rate:${userId}`;
  const count = await redis.incr(key);
  if (count === 1) await redis.expire(key, 60); // 60 seconds window
  if (count > 100) throw new Error('Rate limit exceeded');
}
```

---

### 215. Design a real-time analytics system for tracking user behavior.
**Answer:**
- Use event streaming (Kafka) to collect analytics events.
- Process events with stream processors (Apache Flink, Node.js workers).
- Store aggregated data in a time-series database (InfluxDB, TimescaleDB).
- Expose analytics via REST or WebSocket APIs.

```javascript
// Example: Sending events to Kafka
const { Kafka } = require('kafkajs');
const kafka = new Kafka({ brokers: ['kafka1:9092'] });
const producer = kafka.producer();

await producer.connect();
await producer.send({
  topic: 'analytics',
  messages: [{ value: JSON.stringify({ userId, action, timestamp: Date.now() }) }],
});
```

---

### 216. How would you implement a distributed job queue system for processing background tasks?
**Answer:**
- Use a message broker (RabbitMQ, Redis, SQS) for job distribution.
- Use worker processes to consume and process jobs.
- Ensure job idempotency and retry on failure.
- Monitor job status and failures.

```javascript
// Example: Using Bull (Redis-based queue)
const Queue = require('bull');
const jobQueue = new Queue('jobs', 'redis://127.0.0.1:6379');

jobQueue.process(async (job) => {
  // Process job data
  await doWork(job.data);
});

// Add job
jobQueue.add({ type: 'email', to: 'user@example.com' });
```

---

### 217. Design a scalable WebSocket system for real-time gaming.
**Answer:**
- Use multiple Node.js servers behind a load balancer.
- Use Redis Pub/Sub to synchronize messages between servers.
- Use sticky sessions to keep users on the same server.
- Scale horizontally as user count grows.

```javascript
// Example: Socket.IO with Redis adapter
const io = require('socket.io')(server);
const redisAdapter = require('socket.io-redis');
io.adapter(redisAdapter({ host: 'localhost', port: 6379 }));
```

---

### 218. How would you implement a distributed session management system?
**Answer:**
- Store session data in a shared store (Redis, Memcached).
- Use session IDs in cookies or tokens.
- Ensure session data is replicated and available across all servers.

```javascript
const session = require('express-session');
const RedisStore = require('connect-redis')(session);

app.use(session({
  store: new RedisStore({ client: redisClient }),
  secret: 'mySecret',
  resave: false,
  saveUninitialized: false
}));
```

---

### 219. Design a scalable API gateway that can handle millions of requests.
**Answer:**
- Use NGINX or Envoy as a reverse proxy and load balancer.
- Implement authentication, rate limiting, and logging at the gateway.
- Use service discovery for backend services.
- Scale horizontally and use caching for frequent requests.

```nginx
# Example: NGINX config for API gateway
http {
  upstream backend {
    server backend1:3000;
    server backend2:3000;
  }
  server {
    listen 80;
    location /api/ {
      proxy_pass http://backend;
      proxy_set_header Host $host;
    }
  }
}
```

---

### 220. How would you implement a distributed configuration management system?
**Answer:**
- Store configuration in a distributed key-value store (etcd, Consul, ZooKeeper).
- Use a watcher to detect config changes and reload dynamically.
- Secure sensitive config values (encryption, access control).

```javascript
// Example: Fetching config from Consul
const consul = require('consul')();
consul.kv.get('myapp/config', (err, result) => {
  if (err) throw err;
  const config = JSON.parse(result.Value);
  // Use config in your app
});
```

# Advanced Scalability and Performance (221-230)

### 221. How would you optimize a Node.js application to handle 100K concurrent connections?
**Answer:**
- Use non-blocking, asynchronous code everywhere.
- Use a reverse proxy (NGINX) for connection handling.
- Use clustering to utilize all CPU cores.
- Offload static assets to a CDN.
- Monitor and tune the event loop and garbage collection.

```javascript
const cluster = require('cluster');
const os = require('os');
if (cluster.isMaster) {
  for (let i = 0; i < os.cpus().length; i++) cluster.fork();
} else {
  // Worker: handle requests
  app.listen(3000);
}
```

---

### 222. Explain strategies for horizontal scaling of Node.js applications across multiple regions.
**Answer:**
- Deploy instances in multiple regions using cloud providers.
- Use a global load balancer (e.g., AWS Route 53, Cloudflare) for geo-routing.
- Replicate databases and caches across regions.
- Use CDN for static content.
- Synchronize configuration and secrets securely.

---

### 223. How would you implement a distributed logging system for a microservices architecture?
**Answer:**
- Use a centralized log aggregator (ELK stack, Graylog, or Loki).
- Send logs from each service to the aggregator via syslog, HTTP, or a log shipper (Filebeat, Fluentd).
- Structure logs as JSON for easy parsing.

```javascript
const winston = require('winston');
require('winston-logstash');
const logger = winston.createLogger({
  transports: [
    new winston.transports.Logstash({
      port: 5000,
      node_name: 'my-service',
      host: 'logstash-server'
    })
  ]
});
logger.info('User created', { userId: 123 });
```

---

### 224. What strategies would you use for database scaling in a high-traffic application?
**Answer:**
- Use read replicas for scaling reads.
- Shard data across multiple databases for write scaling.
- Use caching (Redis, Memcached) for frequent queries.
- Optimize queries and add proper indexes.
- Use connection pooling.

---

### 225. How would you implement a distributed cache invalidation system?
**Answer:**
- Use cache versioning or keys with timestamps.
- Use Pub/Sub (Redis, Kafka) to broadcast invalidation events.
- Invalidate cache on all nodes when data changes.

```javascript
// Example: Redis Pub/Sub for cache invalidation
const redis = require('redis');
const pub = redis.createClient();
const sub = redis.createClient();

sub.subscribe('cache-invalidate');
sub.on('message', (channel, key) => {
  cache.del(key); // Remove from local cache
});

function invalidateCache(key) {
  pub.publish('cache-invalidate', key);
}
```

---

### 226. Explain how to handle database connection pooling at scale.
**Answer:**
- Use a connection pool library (e.g., `pg-pool`, `mysql2`, `mongoose`).
- Tune pool size based on workload and DB limits.
- Reuse connections and close idle ones.
- Monitor pool health and handle pool exhaustion gracefully.

```javascript
const { Pool } = require('pg');
const pool = new Pool({ max: 20, idleTimeoutMillis: 30000 });

app.get('/users', async (req, res) => {
  const client = await pool.connect();
  try {
    const result = await client.query('SELECT * FROM users');
    res.json(result.rows);
  } finally {
    client.release();
  }
});
```

---

### 227. How would you implement a distributed task scheduler?
**Answer:**
- Use a distributed message queue (RabbitMQ, Redis, SQS) to distribute tasks.
- Use a distributed lock (Redlock, etcd) to avoid duplicate execution.
- Store task metadata in a shared database.
- Monitor and retry failed tasks.

---

### 228. What strategies would you use for handling memory leaks in production?
**Answer:**
- Use monitoring tools (clinic.js, heapdump, New Relic) to detect leaks.
- Analyze heap snapshots for retained objects.
- Use process restarts (with PM2 or Kubernetes) as a temporary mitigation.
- Fix code issues causing leaks (e.g., event listeners, global variables).

---

### 229. How would you implement a distributed configuration management system?
**Answer:**
- Use a distributed key-value store (Consul, etcd).
- Services fetch config at startup and watch for changes.
- Secure sensitive config with encryption and RBAC.

---

### 230. Explain strategies for handling database sharding.
**Answer:**
- Use consistent hashing or range-based sharding to distribute data.
- Maintain a shard map for routing queries.
- Handle cross-shard queries at the application layer.
- Monitor shard health and rebalance as needed.

```javascript
// Example: Shard map for routing
const shardMap = {
  shard1: { host: 'db1', range: [0, 4999] },
  shard2: { host: 'db2', range: [5000, 9999] }
};
function getShard(userId) {
  const id = parseInt(userId, 10);
  return id < 5000 ? shardMap.shard1 : shardMap.shard2;
}
```

# Advanced Architecture Patterns (231-240)

### 231. How would you design a microservices architecture using Node.js?
**Answer:**
- Decompose the application into independent services, each with its own database.
- Use REST or gRPC for inter-service communication.
- Use an API gateway for routing, authentication, and aggregation.
- Deploy services independently using containers (Docker, Kubernetes).
- Implement service discovery and centralized logging/monitoring.

---

### 232. Explain strategies for service discovery in a microservices architecture.
**Answer:**
- Use a service registry (Consul, etcd, Eureka) where services register themselves.
- Clients query the registry to find service instances.
- Use DNS-based discovery for simple setups.
- API gateways can also handle service discovery.

```javascript
// Example: Registering with Consul
const consul = require('consul')();
consul.agent.service.register({ name: 'users', port: 3001 }, (err) => {
  if (err) throw err;
});
```

---

### 233. How would you implement inter-service communication in a distributed system?
**Answer:**
- Use HTTP/REST or gRPC for synchronous calls.
- Use message queues (RabbitMQ, Kafka, NATS) for asynchronous communication.
- Use circuit breakers and retries for reliability.

```javascript
// Example: HTTP call between services
const axios = require('axios');
const response = await axios.get('http://orders:3002/api/orders');
```

---

### 234. What strategies would you use for handling distributed transactions?
**Answer:**
- Use the Saga pattern for long-running transactions.
- Use two-phase commit (2PC) for strict consistency (less common in microservices).
- Ensure idempotency for retrying operations.

---

### 235. How would you implement a circuit breaker pattern?
**Answer:**
- Use libraries like `opossum` or `brakes` in Node.js.
- Circuit breaker opens after a threshold of failures, blocks requests, and retries after a timeout.

```javascript
const CircuitBreaker = require('opossum');
async function fetchData() { /* ... */ }
const breaker = new CircuitBreaker(fetchData, { errorThresholdPercentage: 50, resetTimeout: 30000 });
breaker.fallback(() => 'Fallback data');
```

---

### 236. Explain how to handle service versioning in microservices.
**Answer:**
- Use versioned API endpoints (e.g., `/v1/users`).
- Support multiple versions in parallel during migration.
- Use semantic versioning for service releases.
- Communicate deprecation timelines to consumers.

---

### 237. How would you implement a service mesh?
**Answer:**
- Use a service mesh like Istio or Linkerd for traffic management, security, and observability.
- Deploy sidecar proxies (Envoy) with each service instance.
- Configure mesh policies for retries, circuit breaking, and mTLS.

---

### 238. What strategies would you use for handling distributed tracing?
**Answer:**
- Use tracing tools (Jaeger, Zipkin, OpenTelemetry).
- Propagate trace IDs in HTTP headers between services.
- Collect and visualize traces for performance analysis.

```javascript
// Example: Using OpenTelemetry
const { NodeTracerProvider } = require('@opentelemetry/sdk-trace-node');
const provider = new NodeTracerProvider();
provider.register();
```

---

### 239. How would you implement a distributed configuration system?
**Answer:**
- Store config in a distributed key-value store (Consul, etcd).
- Services fetch config at startup and watch for changes.
- Secure sensitive config with encryption and RBAC.

---

### 240. Explain how to handle service decomposition.
**Answer:**
- Identify bounded contexts and split by business capability.
- Ensure each service has a single responsibility and its own data store.
- Use APIs for communication between services.
- Refactor monoliths incrementally, extracting services one at a time.

```

# Advanced Security and Authentication (241-250)

### 241. How would you implement a secure authentication system for a large-scale application?
**Answer:**
- Use JWT or OAuth 2.0 for stateless authentication.
- Store passwords securely using bcrypt or argon2.
- Use HTTPS everywhere and secure cookies.
- Implement multi-factor authentication (MFA).
- Rate limit login attempts to prevent brute force attacks.

```javascript
const bcrypt = require('bcrypt');
const jwt = require('jsonwebtoken');

// Hash password
const hash = await bcrypt.hash(password, 12);

// Verify password
const match = await bcrypt.compare(password, hash);

// Generate JWT
const token = jwt.sign({ userId }, process.env.JWT_SECRET, { expiresIn: '1h' });
```

---

### 242. Explain how to prevent common security vulnerabilities in Node.js applications.
**Answer:**
- Sanitize and validate all user input.
- Use parameterized queries to prevent SQL injection.
- Use helmet to set secure HTTP headers.
- Escape output to prevent XSS.
- Use CSRF tokens for state-changing requests.

---

### 243. How would you implement a secure file upload system?
**Answer:**
- Validate file type and size on both client and server.
- Store files outside the web root.
- Rename files to avoid collisions and path traversal.
- Scan files for malware.
- Use signed URLs for direct uploads to cloud storage.

```javascript
const multer = require('multer');
const path = require('path');
const storage = multer.diskStorage({
  destination: (req, file, cb) => cb(null, '/uploads'),
  filename: (req, file, cb) => cb(null, Date.now() + path.extname(file.originalname))
});
const upload = multer({ storage, limits: { fileSize: 5 * 1024 * 1024 } });

app.post('/upload', upload.single('file'), (req, res) => {
  res.json({ file: req.file.filename });
});
```

---

### 244. What strategies would you use for API security?
**Answer:**
- Use API keys or OAuth tokens for authentication.
- Implement rate limiting and IP whitelisting.
- Use HTTPS and validate all input.
- Log and monitor API usage for anomalies.

---

### 245. How would you implement a secure session management system?
**Answer:**
- Store session IDs in secure, HTTP-only cookies.
- Use a server-side session store (Redis, Memcached).
- Regenerate session IDs after login.
- Set appropriate cookie attributes (Secure, SameSite, HttpOnly).

```javascript
const session = require('express-session');
app.use(session({
  secret: process.env.SESSION_SECRET,
  resave: false,
  saveUninitialized: false,
  cookie: { secure: true, httpOnly: true, sameSite: 'strict' }
}));
```

---

### 246. Explain how to handle secure password storage at scale.
**Answer:**
- Use strong hashing algorithms (bcrypt, argon2) with a high work factor.
- Store only the hash and a unique salt per user.
- Never log or transmit plain-text passwords.
- Regularly audit and rotate credentials.

---

### 247. How would you implement a secure API key management system?
**Answer:**
- Generate cryptographically secure API keys.
- Store hashes of API keys, not the keys themselves.
- Allow key rotation and revocation.
- Log usage and alert on suspicious activity.

---

### 248. What strategies would you use for preventing DDoS attacks?
**Answer:**
- Use rate limiting and IP blacklisting.
- Deploy a Web Application Firewall (WAF).
- Use a CDN to absorb traffic spikes.
- Monitor traffic and set up automated alerts.

```javascript
const rateLimit = require('express-rate-limit');
app.use(rateLimit({ windowMs: 60 * 1000, max: 100 }));
```

---

### 249. How would you implement a secure WebSocket connection?
**Answer:**
- Use the `wss://` protocol (WebSocket over TLS).
- Authenticate users before upgrading the connection.
- Validate all incoming messages.
- Use origin checks to prevent cross-site attacks.

```javascript
const https = require('https');
const fs = require('fs');
const WebSocket = require('ws');
const server = https.createServer({
  cert: fs.readFileSync('cert.pem'),
  key: fs.readFileSync('key.pem')
});
const wss = new WebSocket.Server({ server });

wss.on('connection', (ws, req) => {
  // Authenticate user here
});
```

---

### 250. Explain how to handle secure data encryption at rest and in transit.
**Answer:**
- Use HTTPS/TLS for all network communication.
- Encrypt sensitive data before storing it (AES, RSA).
- Use managed key services (AWS KMS, Azure Key Vault) for key management.
- Regularly rotate encryption keys and audit access.

```javascript
const crypto = require('crypto');
const key = crypto.randomBytes(32);
const iv = crypto.randomBytes(16);

function encrypt(text) {
  const cipher = crypto.createCipheriv('aes-256-cbc', key, iv);
  let encrypted = cipher.update(text, 'utf8', 'hex');
  encrypted += cipher.final('hex');
  return encrypted;
}

function decrypt(encrypted) {
  const decipher = crypto.createDecipheriv('aes-256-cbc', key, iv);
  let decrypted = decipher.update(encrypted, 'hex', 'utf8');
  decrypted += decipher.final('utf8');
  return decrypted;
}
```
